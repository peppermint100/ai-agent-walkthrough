"""
Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ë™ê¸° + ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ ìŠ¤íŠ¸ë¦¬ë° ì±—ë´‡
- ë¹„ë™ê¸° ë°©ì‹ìœ¼ë¡œ API í˜¸ì¶œ
- tenacityë¥¼ ì‚¬ìš©í•œ ìë™ ì¬ì‹œë„ (ìµœëŒ€ 3ë²ˆ, 1ì´ˆ ê°„ê²©)
- 50% í™•ë¥ ë¡œ ì‹¤íŒ¨ ì‹œë®¬ë ˆì´ì…˜ (í…ŒìŠ¤íŠ¸ìš©)
"""
import os
import asyncio
import random
from pathlib import Path
import google.generativeai as genai
from dotenv import load_dotenv
from tenacity import (
    retry,
    stop_after_attempt,
    wait_fixed,
    retry_if_exception_type
)
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# í…ŒìŠ¤íŠ¸ìš© ì‹¤íŒ¨ ì‹œë®¬ë ˆì´ì…˜ í”Œë˜ê·¸
SIMULATE_FAILURE = True  # Trueë¡œ ì„¤ì •í•˜ë©´ 50% í™•ë¥ ë¡œ ìš”ì²­ ì‹¤íŒ¨

# .env íŒŒì¼ ê²½ë¡œ ì„¤ì •
env_path = Path(__file__).parent.parent / '.env'
if not env_path.exists():
    env_path = Path(__file__).parent / '.env'

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv(dotenv_path=env_path)

# Gemini API í‚¤ ì„¤ì •
api_key = os.getenv("GEMINI_API_KEY")
if not api_key:
    raise ValueError(
        "GEMINI_API_KEY í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.\n"
        ".env íŒŒì¼ì„ ìƒì„±í•˜ê³  GEMINI_API_KEYë¥¼ ì„¤ì •í•˜ê±°ë‚˜, "
        ".env.example íŒŒì¼ì„ ì°¸ê³ í•˜ì„¸ìš”."
    )

genai.configure(api_key=api_key)

# ëª¨ë¸ ì´ˆê¸°í™”
model = genai.GenerativeModel('gemini-2.5-flash')


def _should_fail():
    """50% í™•ë¥ ë¡œ ì‹¤íŒ¨ ì‹œë®¬ë ˆì´ì…˜"""
    if SIMULATE_FAILURE:
        will_fail = random.random() < 0.9
        if will_fail:
            print("ğŸ”´ ì‹œë®¬ë ˆì´ì…˜: API í˜¸ì¶œ ì‹¤íŒ¨!", flush=True)
        return will_fail
    return False


def _log_retry_attempt(retry_state):
    """ì¬ì‹œë„ ì „ì— í˜¸ì¶œë˜ëŠ” ì½œë°± í•¨ìˆ˜"""
    attempt_number = retry_state.attempt_number
    print(f"\nâš ï¸  ì¬ì‹œë„ {attempt_number}ë²ˆì§¸ - 1ì´ˆ í›„ ë‹¤ì‹œ ì‹œë„í•©ë‹ˆë‹¤...", flush=True)


@retry(
    stop=stop_after_attempt(3),  # ìµœëŒ€ 3ë²ˆ ì‹œë„ (ì²« ì‹œë„ + 2ë²ˆ ì¬ì‹œë„)
    wait=wait_fixed(1),  # 1ì´ˆ ê°„ê²©
    retry=retry_if_exception_type(Exception),
    before_sleep=_log_retry_attempt
)
async def _get_api_response(question: str):
    """
    ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ API í˜¸ì¶œ í•¨ìˆ˜

    Args:
        question: ì§ˆë¬¸ ë‚´ìš©

    Returns:
        API ì‘ë‹µ ê°ì²´
    """
    # ì‹¤íŒ¨ ì‹œë®¬ë ˆì´ì…˜
    if _should_fail():
        raise Exception("Simulated API failure - ì¬ì‹œë„ ì¤‘...")

    print("âœ… API í˜¸ì¶œ ì„±ê³µ - ë‹µë³€ ìƒì„± ì¤‘...", flush=True)
    # ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ API í˜¸ì¶œ
    response = await model.generate_content_async(question, stream=True)
    return response


async def ask_question_stream(question: str):
    """
    ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ë‹µë³€ì„ ë°›ëŠ” í•¨ìˆ˜

    Args:
        question: ì§ˆë¬¸ ë‚´ìš©

    Yields:
        ë‹µë³€ì˜ ê° ì²­í¬(chunk)
    """
    try:
        # ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ API í˜¸ì¶œ
        response = await _get_api_response(question)

        # ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ê° ì²­í¬ë¥¼ ë°›ì•„ì„œ yield
        async for chunk in response:
            if chunk.text:
                yield chunk.text

    except Exception as e:
        # ì¬ì‹œë„ ë¡œì§ì—ì„œ ì²˜ë¦¬ë˜ì§€ ì•Šì€ ì˜ˆì™¸
        logger.error(f"âŒ API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        raise


async def main():
    """ë©”ì¸ ë¹„ë™ê¸° í•¨ìˆ˜"""
    print("=" * 60)
    print("Gemini ë¹„ë™ê¸° + ì¬ì‹œë„ ìŠ¤íŠ¸ë¦¬ë° ì±—ë´‡")
    print("(ë¹„ë™ê¸° ë°©ì‹ + ìë™ ì¬ì‹œë„ + ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°)")
    print(f"í…ŒìŠ¤íŠ¸ ëª¨ë“œ: {'í™œì„±í™” (50% ì‹¤íŒ¨ ì‹œë®¬ë ˆì´ì…˜)' if SIMULATE_FAILURE else 'ë¹„í™œì„±í™”'}")
    print("ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ë˜ëŠ” 'exit'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    print("=" * 60)

    while True:
        # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸° (ë™ê¸° ë°©ì‹ì´ì§€ë§Œ ë¬¸ì œì—†ìŒ)
        user_input = input("\nì§ˆë¬¸: ").strip()

        # ì¢…ë£Œ ì¡°ê±´
        if user_input.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
            print("ì±„íŒ…ì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ì•ˆë…•íˆ ê°€ì„¸ìš”!")
            break

        # ë¹ˆ ì…ë ¥ ì²˜ë¦¬
        if not user_input:
            print("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            continue

        # ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë‹µë³€ ë°›ê¸°
        print("\në‹µë³€: ", end='', flush=True)

        try:
            async for chunk in ask_question_stream(user_input):
                print(chunk, end='', flush=True)
            print()  # ì¤„ë°”ê¿ˆ

        except Exception as e:
            print(f"\n\nì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            print("ì¬ì‹œë„ íšŸìˆ˜ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")


if __name__ == "__main__":
    # ë¹„ë™ê¸° ë©”ì¸ í•¨ìˆ˜ ì‹¤í–‰
    asyncio.run(main())
